{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Architectures / Prompting Techniques \n",
    "\n",
    "Advanced techniques of applying LLM to usecases include changes to the architecture of a basic LLM and/or unique prompting techniques and often a combination of both. \n",
    "\n",
    "(Part 1)\n",
    " - Chain of Thought (CoT)\n",
    " - ReAct\n",
    " - OpenAI Function Calling\n",
    " - Prompt Chaining\n",
    " \n",
    "(Part 2)\n",
    " - RAG\n",
    " - Tree of Thoughts (ToT)\n",
    " - Self-Consistency\n",
    " - Self-Ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "my_key = \"voc-863264702126677398047467ee2c4e76d1d8.74527469\"\n",
    "# my_key = \"test\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"https://openai.vocareum.com/v1\",\n",
    "    api_key = my_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM function call\n",
    "def get_response(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=512):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain of Thought\n",
    "**Note**: LLMs dont think and reason as technique name suggests. This technique simply triggers a slightly different response that enables arriving at the right answer. \n",
    " - Tells the model to think step by step before answering. Why? Improves reasoning, math, logic, and complex decision tasks.\n",
    " - As simple as, telling it to think in steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, let's plan out the steps carefully to ensure that the fox, goose, and bag of beans all cross the river safely.\n",
      "\n",
      "Step 1: The farmer takes the goose across the river and leaves it on the other side.\n",
      "Step 2: The farmer goes back to the original side alone, leaving the goose on the other side.\n",
      "Step 3: The farmer takes the fox across the river.\n",
      "Step 4: The farmer leaves the fox on the other side and takes the goose back with him to the original side.\n",
      "Step 5: The farmer leaves the goose on the original side and takes the bag of beans across the river.\n",
      "Step 6: The farmer leaves the bag of beans with the fox on the other side and goes back to the original side alone.\n",
      "Step 7: Finally, the farmer takes the goose across the river one last time.\n",
      "\n",
      "By following these steps, the farmer can successfully transport the fox, goose, and bag of beans across the river without any of them being eaten.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant who addresses queries in any topic\"\n",
    "user_prompt = \"\"\"A farmer needs to cross a river with a fox, a goose, and a bag of beans.\n",
    "He has a boat, but it can only carry him and one other item at a time.\n",
    "If left alone together then The fox will eat the goose and The goose will eat the beans.\n",
    "How can the farmer get all three across safely?\n",
    "Let's think through each step one by one to ensure nothing is eaten.\"\"\"\n",
    "\n",
    "messages=[\n",
    "          {\"role\": \"system\",\"content\": system_prompt},\n",
    "          {\"role\": \"user\",\"content\": user_prompt}\n",
    "          ]\n",
    "\n",
    "response = get_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct Technique\n",
    "ReAct is using the “reasoning and acting” (ReAct) framework to combine chain of thought (CoT) reasoning with external tool use.\n",
    "- ReAct can be understood most generally as a machine learning (ML) paradigm to integrate the reasoning and action-taking capabilities of LLMs.\n",
    "- It has been extended to AI Agents which use this conceptual framework a lot\n",
    "- ReAct framework uses prompt engineering to structure LLMs activity in a formal pattern of alternating thoughts, actions and observations.\n",
    "- Reference : https://www.ibm.com/think/topics/react-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Without ReACT Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several ways to determine if your diet is improving your wellness. Here are some tips to help you assess the impact of your diet on your overall well-being:\n",
      "\n",
      "1. **Energy levels**: Pay attention to your energy levels throughout the day. A well-balanced diet that includes a variety of nutrients should provide you with sustained energy levels and help you feel more alert and focused.\n",
      "\n",
      "2. **Mood**: Your diet can also have an impact on your mood. Notice if you feel more positive, less irritable, or more emotionally balanced after making changes to your diet.\n",
      "\n",
      "3. **Digestive health**: A healthy diet should support good digestion and regular bowel movements. If you experience less bloating, gas, or indigestion, it could be a sign that your diet is benefiting your digestive health.\n",
      "\n",
      "4. **Weight management**: If weight management is a goal for you, tracking your weight and body measurements can help you determine if your diet is supporting your goals.\n",
      "\n",
      "5. **Physical health**: Improved physical health can be a good indicator that your diet is working for you. This can include improvements in blood pressure, cholesterol levels, and blood sugar levels.\n",
      "\n",
      "6. **Skin health**: Your skin can also reflect the state of your diet. If you notice improvements in your skin, such as clearer complexion or reduced acne, it could be a sign that your diet is benefiting your skin health.\n",
      "\n",
      "7. **Overall well-being**: Pay attention to how you feel overall. If you feel more vibrant, have better immunity, and experience fewer aches and pains, it could be a sign that your diet is contributing to your overall wellness.\n",
      "\n",
      "Remember that everyone's body is different, so it's important to listen to your own body and make adjustments to your diet based on how you feel. If you have specific wellness goals or concerns, consider consulting with a healthcare provider or a registered dietitian for personalized guidance.\n"
     ]
    }
   ],
   "source": [
    "# Creating the prompt\n",
    "system_prompt = \"You are a helpful Wellness assistant with a goal to improve the wellness of the user\"\n",
    "user_prompt = \"How can I know my diet is improving my wellness?\"\n",
    "\n",
    "\n",
    "messages=[\n",
    "          {\"role\": \"system\",\"content\": system_prompt},\n",
    "          {\"role\": \"user\",\"content\": user_prompt}\n",
    "          ]\n",
    "\n",
    "response = get_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With ReACT Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Thought) User is interested in understanding how their diet impacts their overall wellness.\n",
      "\n",
      "Collect[Details about user's current diet]: What does a typical day of eating look like for you? Do you have any specific dietary preferences or restrictions?\n",
      "\n",
      "Provide[Wellness Information]: A balanced diet plays a crucial role in improving overall wellness. It should include a variety of fruits, vegetables, whole grains, lean proteins, and healthy fats. Monitoring how your body feels, your energy levels, digestion, and mood can give you insights into how your diet is affecting your wellness.\n",
      "\n",
      "Recommend[Plan]: To assess if your diet is improving your wellness, consider keeping a food journal to track what you eat and how you feel after eating. Look for patterns in your energy levels, mood, and any physical symptoms. You can also consult with a nutritionist or dietitian for personalized guidance on how to optimize your diet for better wellness outcomes.\n",
      "\n",
      "Observation: How do you feel after meals? Are there any specific symptoms or changes you notice in your body based on what you eat? Would you be interested in keeping a food journal to track your diet and wellness outcomes?\n"
     ]
    }
   ],
   "source": [
    "system_prompt =\"\"\"Your goal is to improve the wellness of the user by interleaving thought, action, and observation steps.\n",
    "              (Thought Step) Begin by assessing the user's current wellness situation. Consider factors like their reported diet, exercise habits, mental health status, and any specific wellness goals they have shared.\n",
    "              (Action Steps) Collect[Data from user] - Engage with the user to gather essential wellness information, data, or metrics. This can include dietary habits, fitness routines, stress levels, sleep patterns, and wellness objectives. \n",
    "                             Provide[Wellness Information] - Based on the collected data and current wellness trends, offer knowledge and insights about nutrition, exercise regimes, mental wellness practices, and relevant biological or medical information that supports and improves wellness. \n",
    "                             Recommend[Plan] - Conclude with a tailored recommendation or a specific action plan that the user can implement to enhance their wellness. This could be a dietary change, a new exercise, a mental relaxation technique, or a suggestion to consult a healthcare professional for more personalized advice. \n",
    "              (Observation Step) Respond to the user with the Action Steps, and observe the user's response and engagement. Gauge their understanding and willingness to follow the suggestions. Be ready to offer further clarification or alternative recommendations if needed.\n",
    "              Repeat these steps N times until the user's wellness has improved.\n",
    "              Example: \n",
    "              [User Query] I'm feeling stressed and not sleeping well. What can I do to improve my sleep? \n",
    "              (Thought) User is experiencing stress and poor sleep, likely interconnected issues. \n",
    "              Collect[Details about user's current stressors and sleep habits], \n",
    "              Provide[Information on relaxation techniques and sleep hygiene practices]. \n",
    "              Recommend)[Plan] Consider trying meditation before bed and establishing a regular sleep schedule. \n",
    "              What are some current stressors in your life? How many hours of sleep do you get each night?\n",
    "              Have you tried meditation before bed? Do you have a regular sleep schedule?\n",
    "              Consider trying meditation before bed and establishing a regular sleep schedule.\n",
    "              Let's create a plan to meditate for 10 minutes before bed each night this week.\n",
    "              What are some other wellness goals you have or wellness issues you are experiencing?\n",
    "              \"\"\"\n",
    "user_prompt = \"How can I know my diet is improving my wellness?\"\n",
    "\n",
    "\n",
    "messages=[\n",
    "          {\"role\": \"system\",\"content\": system_prompt},\n",
    "          {\"role\": \"user\",\"content\": user_prompt}\n",
    "          ]\n",
    "\n",
    "response = get_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Next to do: https://www.ibm.com/think/tutorials/deploy-langgraph-react-agent-manage-it-support-tickets-watsonx-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Function Calling\n",
    " ReACT Methodology's authors (as in the original paper) suggested that LLM should be able reason and act including making API calls to other programs but there was no such facility until OpenAI added \"Function Calling\" feature. OpenAI fine-tuned its models such that it can recognize the need to call another function and suggests it to the user. \n",
    " - In a typical Function calling workflow, LLM suggests making a function call by naming a function and providing arguments for the function, user triggers the function call on their backend and returns the results back to the LLM as next input. LLM concludes the worlflow with the final word based on the input received. \n",
    "  - Reference: https://openai.com/index/function-calling-and-other-api-updates/\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function schema\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_patient_history\",\n",
    "        \"description\": \"Returns historical health metrics for a patient\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"patient_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unique ID of the patient\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"patient_id\"]\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dummy function that returns patient previous record (hard-coded below for simplicity)\n",
    "def get_patient_history(patient_id):\n",
    "    return {\n",
    "        \"blood_pressure\": \"150/95\",\n",
    "        \"cholesterol\": \"220 mg/dL\",\n",
    "        \"blood_sugar\": \"140 mg/dL\",\n",
    "        \"diagnosis\": \"Hypertension and pre-diabetes\",\n",
    "        \"last_checkup\": \"2024-11-10\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial/ First message to ChatGpt where we expect it to decide on calling a function\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a wellness assistant helping users analyze and improve their health.\n",
    "        If the user asks for comparisons, trends, or historical context, and you do not have that data, use the `get_past_health_metrics` function to retrieve it.\n",
    "        Always call a function when past health data is relevant but missing.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\n",
    "My patient ID is 001. Here are my current metrics: \n",
    "blood pressure is 130/85, cholesterol is 195, and blood sugar is 110.\n",
    "How am I doing compared to my last checkup?\n",
    "\"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FunctionCall(arguments='{\"patient_id\":\"001\"}', name='get_patient_history')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Step 1: Let LLM decide if it wants to call a function\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\"\n",
    ")\n",
    "\n",
    "# Step 2: Handle function call from LLM\n",
    "message = response.choices[0].message\n",
    "\n",
    "print(message.function_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compared to your last checkup on November 10, 2024, there have been improvements in your health metrics. \n",
      "\n",
      "Your current blood pressure is 130/85, which is lower than the previous reading of 150/95. Your cholesterol has decreased from 220 mg/dL to 195 mg/dL, showing progress. Additionally, your blood sugar level has improved from 140 mg/dL to 110 mg/dL.\n",
      "\n",
      "Overall, it appears that your efforts to manage your health have been successful, and you are moving in the right direction. Keep up the good work! If you have any more questions or need further assistance, feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "if message.function_call:\n",
    "    function_name = message.function_call.name\n",
    "    arguments = json.loads(message.function_call.arguments)\n",
    "    \n",
    "    if function_name == \"get_patient_history\":\n",
    "        function_response = get_patient_history(arguments[\"patient_id\"])\n",
    "        \n",
    "        # Step 3: Add function result to messages and call LLM again\n",
    "        messages.extend([\n",
    "            message,\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": json.dumps(function_response)\n",
    "            }\n",
    "        ])\n",
    "        \n",
    "        final_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        print(final_response.choices[0].message.content)\n",
    "    else:\n",
    "        print(\"Unrecognized function.\")\n",
    "else:\n",
    "    print(\"No function call made.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:OpenAI Function Calling**\n",
    "\n",
    "While OpenAI's Function Calling has a key limitation: the responsibility of writing, maintaining, and updating these functions lies entirely with the developer. This is not scalable since a provider might change their API which will lead to errors in our pipeline. \n",
    "\n",
    "Emerging standards like Anthropic’s Model Context Protocol (MCP) and Google’s A2A (Agents-to-Agents) protocol aim to address this by enabling more interoperable and standardized interfaces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Chaining\n",
    "Prompt Chaining is where we have tasks that require multiple calls to the LLM where the output of one call is fed to the next and this is repeated until task is done. An example use case with translating communications to another language, summarizing and writing a response and converting it back to the orginal language (as below.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Sample email in French from a job applicant\n",
    "french_email = \"\"\"\n",
    "Bonjour,  \n",
    "Je m'appelle Claire Dubois et je suis très intéressée par le poste de Data Scientist dans votre entreprise.  \n",
    "J'ai trois ans d'expérience dans l'analyse de données et le développement de modèles prédictifs.  \n",
    "Je suis disponible pour un entretien à votre convenance.  \n",
    "Veuillez trouver mon CV en pièce jointe.  \n",
    "Cordialement,  \n",
    "Claire Dubois\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Translate French → English\n",
    "translate_response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Translate this French email into English:\\n\\n{french_email}\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ").choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Summarize the English email\n",
    "summary_response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize this email:\\n\\n{translate_response}\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ").choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Write a professional reply in English\n",
    "reply_response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Write a professional email reply to this summary:\\n\\n{summary_response}\"}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ").choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: English Translation ===\n",
      "Hello,\n",
      "My name is Claire Dubois and I am very interested in the Data Scientist position in your company.\n",
      "I have three years of experience in data analysis and developing predictive models.\n",
      "I am available for an interview at your convenience.\n",
      "Please find my CV attached.\n",
      "Best regards,\n",
      "Claire Dubois\n",
      "\n",
      "=== Step 2: Summary ===\n",
      "Claire Dubois is interested in the Data Scientist position at the company, with three years of experience in data analysis and developing predictive models. She is available for an interview and has attached her CV for consideration.\n",
      "\n",
      "=== Step 3: English Reply ===\n",
      "Dear Claire,\n",
      "\n",
      "Thank you for your interest in the Data Scientist position at our company. We appreciate your three years of experience in data analysis and developing predictive models. We have received your CV and will review it for consideration. We will be in touch soon to schedule an interview.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Title]\n",
      "[Company Name]\n",
      "\n",
      "=== Step 4: Final French Reply ===\n",
      "Chère Claire,\n",
      "\n",
      "Merci pour votre intérêt pour le poste de Data Scientist dans notre entreprise. Nous apprécions vos trois ans d'expérience en analyse de données et en développement de modèles prédictifs. Nous avons bien reçu votre CV et le passerons en revue pour considération. Nous vous contacterons bientôt pour planifier un entretien.\n",
      "\n",
      "Cordialement,\n",
      "\n",
      "[Votre Nom]\n",
      "[Votre Titre]\n",
      "[Nom de l'entreprise]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Translate the reply back to French\n",
    "translated_reply = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Translate this reply into French:\\n\\n{reply_response}\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ").choices[0].message.content\n",
    "\n",
    "# Final Output\n",
    "print(\"=== Step 1: English Translation ===\")\n",
    "print(translate_response)\n",
    "print(\"\\n=== Step 2: Summary ===\")\n",
    "print(summary_response)\n",
    "print(\"\\n=== Step 3: English Reply ===\")\n",
    "print(reply_response)\n",
    "print(\"\\n=== Step 4: Final French Reply ===\")\n",
    "print(translated_reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
